### 1.Model
model:
  name: "Whole_model_light256_V2"
  backbone: "without-pretrain"
  base_size: 1024    # during augentation, shorter size will be resized between [base_size*0.5, base_size*2.0]
  crop_size: 512   # end of augmentation, crop to trainning

### 2.Optimizer
optimizer:
  init_lr: 0.01
  momentum: 0.9
  weight_decay: 0.0001

### 3.Trainning 
train:
  specific_gpu_num: "0"     # for example: "0", "1" or "0, 1"
  train_batch_size: 4
  # adjust according to gpu resources
  valid_batch_size: 1
#  cityscapes_root: "./datasets/cityscape/leftImg8bit_trainvaltest/"
  cityscapes_root: "E:\\B\\cityscape\\leftImg8bit_trainvaltest"
  epochs: 1000
  log_iter: 10        # print log every log-iter 
  val_epoch: 1        # run validation every val-epoch
  log_save_dir: "./results/log"  #日志保存在这里
  ckpt_dir: "./results/ckpt/" # ckpt and trainning log will be saved here

### 4.Test
test:
  ckpt_path: "D:\\code\\My\\results\\ckpt\\Whole_model_light_without-pretrain_997_0.710_best_model.pth" # set the pretrained model path correctly